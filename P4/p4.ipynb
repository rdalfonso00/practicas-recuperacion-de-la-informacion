{"cells":[{"cell_type":"markdown","metadata":{"id":"F4qwv6V8DiGv"},"source":["# Laboratorio 4"]},{"cell_type":"markdown","metadata":{"id":"PudnwJzRDiG7"},"source":["1. Utilice el archivo generado en el laboratorio 3 con los documentos de la colección de CACM preprocesados.\n","1. Obtengan el vocabulario de la colección utilizando truncamiento. Impriman la longitud del vocabulario. Después de observar el vocabulario resultante, proponga mecanismos para reducirlo. Codifique los mecanismos propuestos. Escriba la longitud del vocabulario reducido. Las longitudes deberán escribirse a pantalla\n","1. Escriban los vocabularios finales a archivos vocabulario.txt y vocabulario_reducido.tx\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Primero extraemos las palabras de documentos_final.txt\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" preliminary report international algebraic language   extraction root repeated subtraction digital computer   technique department matrix program scheme   glossary computer engineering programming terminology  square root approximation   computer inspection procedure   glossary computer engineering programming terminology  equivalence transformation program scheme   proposal uncol   glossary computer engineering programming terminology  problem programming communication changing machine proposed solution part   error estimation runge kutta procedure   glossary computer engineering programming terminology  problem programming communication changing machine proposed solution part   recursive curve fitting technique   secant modification newton method   programming arithmetic operation   simple automatic coding system   glossary computer engineering programming terminology  technique discussed applied iterative procedure solution equation accelerates rate convergence iteration converges \n"]}],"source":["filename = \"documentos_final.txt\"\n","file = open(filename, 'rt',encoding='utf-8-sig')\n","text = file.read()\n","file.close()\n","import re\n","words = re.split(r\"\\n\", text)\n","doc_words = \"\"\n","i = 0\n","for w in words:\n","    split = re.split(r\"\\|\", w)\n","    if len(split) == 1:\n","        continue\n","    elif len(split) == 4:\n","        #doc_data[i]['d_num'] = split[0]\n","        doc_words += split[2] + \" \"\n","    doc_words += split[1] + \" \"\n","    i = i + 1\n","print(doc_words[:1000])"]},{"cell_type":"markdown","metadata":{},"source":["Hacemos lo mismo con querys_final.txt"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" article exist deal tss time sharing system operating system ibm computer  interested article written prieve udo pooch prieve pooch  intermediate language construction multi targeted compiler tcoll  interested mechanism communicating disjoint process possibly exclusively distributed environment description complete mechanism implementation opposed theoretical work abstract problem remote procedure call message passing example interest  paper design implementation editing interface window manager command interpreter essential issue human interface design view improvement user efficiency effectiveness satisfaction  interested article robotics motion planning geometric combinatorial aspect interested dynamic arm motion  interested distributed algorithm concurrent program process communicate synchronize message passing area interest include fault tolerance technique understanding correctness algorithm  addressing scheme resource network resource addressing network operating system  securit\n"]}],"source":["filename = \"querys_final.txt\"\n","file = open(filename, 'rt',encoding='utf-8-sig')\n","text = file.read()\n","file.close()\n","import re\n","words = re.split(r\"\\n\", text)\n","query_words = \"\"\n","i = 0\n","for w in words:\n","    split = re.split(r\"\\|\", w)\n","    if len(split) == 1:\n","        continue\n","    elif len(split) == 4:\n","        #doc_data[i]['d_num'] = split[0]\n","        query_words += split[2] + \" \"\n","    query_words += split[1] + \" \"\n","    i = i + 1\n","print(query_words[:1000])"]},{"cell_type":"markdown","metadata":{},"source":["Unimos y separamos todas las palabras (omitiendo vacías)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['preliminary', 'report', 'international', 'algebraic', 'language', 'extraction', 'root', 'repeated', 'subtraction', 'digital', 'computer', 'technique', 'department', 'matrix', 'program', 'scheme', 'glossary', 'computer', 'engineering', 'programming', 'terminology', 'square', 'root', 'approximation', 'computer', 'inspection', 'procedure', 'glossary', 'computer', 'engineering', 'programming', 'terminology', 'equivalence', 'transformation', 'program', 'scheme', 'proposal', 'uncol', 'glossary', 'computer', 'engineering', 'programming', 'terminology', 'problem', 'programming', 'communication', 'changing', 'machine', 'proposed', 'solution', 'part', 'error', 'estimation', 'runge', 'kutta', 'procedure', 'glossary', 'computer', 'engineering', 'programming', 'terminology', 'problem', 'programming', 'communication', 'changing', 'machine', 'proposed', 'solution', 'part', 'recursive', 'curve', 'fitting', 'technique', 'secant', 'modification', 'newton', 'method', 'programming', 'arithmetic', 'operation', 'simple', 'automatic', 'coding', 'system', 'glossary', 'computer', 'engineering', 'programming', 'terminology', 'technique', 'discussed', 'applied', 'iterative', 'procedure', 'solution', 'equation', 'accelerates', 'rate', 'convergence', 'iteration']\n","91719\n"]}],"source":["all_words = [x for x in (doc_words + \" \" + query_words).split(\" \") if x]\n","print(all_words[:100])\n","print(str(len(all_words)))"]},{"cell_type":"markdown","metadata":{},"source":["Ahora buscaremos reducir el vocabulario existente"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["('preliminary', 'report', 'international', 'algebraic', 'language', 'extraction', 'root', 'repeated', 'subtraction', 'digital')\n","(19, 95, 7, 69, 831, 10, 67, 7, 9, 135)\n","7627\n"]}],"source":["from collections import Counter\n","\n","c = Counter(all_words)\n","#print(c.items())\n","labels, values = zip(*c.items())\n","print(labels[:10])\n","print(values[:10])\n","print(len(labels))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 6.0, 10.0, 24.0]\n"]}],"source":["# vemos los datos en deciles\n","import statistics\n","deciles = statistics.quantiles(values, n=10)\n","print(deciles)"]},{"cell_type":"markdown","metadata":{},"source":["Viendo la distribución de los datos en deciles, vemos que la casi mitad de las palabras del vocabulario aparecen en frecuencias cercanas a 1 y 2.\n","\n","Se optará por eliminar solamente las palabras con 1 ocurrencia en el vocabulario."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4750\n","We deleted 2877 words from the vocabulary\n"]}],"source":["reduced_words = {k: v for k, v in c.items() if v != 1}\n","print(len(reduced_words))\n","print(\"We deleted \" + str(len(labels) - len(reduced_words)) + \" words from the vocabulary\")"]},{"cell_type":"markdown","metadata":{},"source":["Vemos que se eliminaron 2877 palabras, que a mi consideración fueron demasiadas, seguiremos revisando el vocabulario existente.\n","\n","Analizaremos la distribución del largo de los términos del vocabulario."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["[(1, 26),\n"," (2, 783),\n"," (3, 2357),\n"," (4, 9335),\n"," (5, 9024),\n"," (6, 12533),\n"," (7, 13352),\n"," (8, 13418),\n"," (9, 12493),\n"," (10, 7177),\n"," (11, 6143),\n"," (12, 2353),\n"," (13, 1357),\n"," (14, 1003),\n"," (15, 194),\n"," (16, 133),\n"," (17, 23),\n"," (18, 11),\n"," (19, 1),\n"," (20, 3)]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len_freq_dict = dict()\n","for w in all_words:\n","    len_freq_dict[len(w)] = 0\n","for w in all_words:\n","    len_freq_dict[len(w)] = len_freq_dict[len(w)] + 1\n","len_freq_list = (sorted(len_freq_dict.items()))\n","len_freq_list"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["13.629673241095084\n"]}],"source":["x = len_freq_list[0][1] +len_freq_list[1][1] + len_freq_list[2][1] + len_freq_list[3][1]\n","print(str(x / len(all_words) * 100))"]},{"cell_type":"markdown","metadata":{},"source":["Aquí ya vemos que las palabras con 1, 2, 3 y 4 caracteres que existen en el vocabulario conforman el 13.6% del diccionario, por lo que estas serán las que se eliminarán"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["We deleted 1106 words from the vocabulary\n"]}],"source":["reduced_words = {k: v for k, v in c.items() if len(k) > 4}\n","print(\"We deleted \" + str(len(labels) - len(reduced_words)) + \" words from the vocabulary\")"]},{"cell_type":"markdown","metadata":{},"source":["Por último, las palabras serán escritas a vocabulario.txt y vocabulario_reducido.txt"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["voc = ', '.join(list(labels))\n","reduced_voc = ', '.join(list(reduced_words.keys()))\n","with open('vocabulario.txt', 'w') as f:\n","    f.write(voc)\n","    f.close()\n","with open('vocabulario_reducido.txt', 'w') as f:\n","    f.write(reduced_voc)\n","    f.close()"]},{"cell_type":"markdown","metadata":{},"source":["## Test con truncamiento\n","Todo el código anterior procesa un vocabulario creado con lematización, como prueba, se realizó el mismo procesamiento con un vocabulario creado a partir de truncamiento con el algoritmo de porter. Este se encuentra en los archivos **documentos_trunc.txt** y **querys_trunc.txt**\n","\n","El script se ejecuta en una terminal en este directorio de la forma: \n",">\\>python p4.py\n","\n","Los resultados fueron los siguientes:\n","\n","![Resultados procesamiento vocabulario con truncamiento](test_trunc.png)\n","\n","Vemos que el vocabulario inicial comienza en 5250 palabras, ¡una reducción de casi de 2000 palabras en contraste con el vocabulario con lematización!\n","\n","Se observa también que si buscamos eliminar palabras con 1 sola ocurrencia nos topamos con la misma situación que con lematización, el vocabulario se reduciría demasiado (más de la mitad), por lo que la opción de eliminar por largo será la más adecuada en este caso.\n","\n","Podemos solamente omitr palabras de largo = {1,2,3} y no de 4 también, eliminando el 9.85% del vocabulario de esta forma."]}],"metadata":{"colab":{"name":"p1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"8bac3ed83652cd3fb2be2ab4720f126b858190479445937cf7f7241afc53dfb0"}}},"nbformat":4,"nbformat_minor":0}
