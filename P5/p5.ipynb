{"cells":[{"cell_type":"markdown","metadata":{"id":"F4qwv6V8DiGv"},"source":["# Laboratorio 5\n","\n","1. Utilice los archivos pre-procesados que obtuvo en la práctica 3, mismos que almacenan la colección CACM y los queries.\n","2. Si en la práctica tres generó el vocabulario sin ordenarlo alfabéticamente ordénelo, tanto el normal como el reducido.\n","3. Represente cada documento empleando el modelo vectorial y el esquema de pesado tf. Recuerde que la dimensión de los vectores será igual al tamaño del vocabulario que obtuvo en la práctica 4. Trabajen con el vocabulario sin reducir y después reducido. Guarda las matrices generada, que representa los documentos de la colección, para utilizarla en prácticas posteriores.\n","4. Utiliza el archivo de queries y represéntelos también empleando el modelo vectorial y esquema de pesado tf. Con vocabulario normal y reducido. Guarda las matrices generadas."]},{"cell_type":"markdown","metadata":{},"source":["Primero extraemos las palabras de documentos_final.txt\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['preliminari', 'report', 'intern', 'algebra', 'languag', 'extract', 'root', 'repeat', 'subtract', 'digit']\n","3204\n"]}],"source":["filename = \"documentos_trunc.txt\"\n","file = open(filename, 'rt',encoding='utf-8-sig')\n","text = file.read()\n","file.close()\n","import re\n","words = re.split(r\"\\n\", text)\n","doc_words = \"\"\n","doc_count = 0\n","for w in words:\n","    split = re.split(r\"\\|\", w)\n","    if len(split) == 1:\n","        continue\n","    elif len(split) == 4:\n","        #doc_data[i]['d_num'] = split[0]\n","        doc_words += split[2] + \" \"\n","    doc_words += split[1] + \" \"\n","    doc_count += 1\n","doc_words = [x for x in (doc_words).split(\" \") if x]\n","print(doc_words[:10])\n","print(doc_count)"]},{"cell_type":"markdown","metadata":{},"source":["Luego, importamos el vocabulario creado en la práctica 4."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["filename = \"vocabulario_trunc.txt\"\n","file = open(filename, 'rt',encoding='utf-8-sig')\n","vocabulary = file.read().split(\", \")\n","file.close()\n","vocabulary = sorted(vocabulary)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, comenzamos los cálculos para la representación del vocabulario por medio del modelo vectorial."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["{'1604a': 1,\n"," '16th': 1,\n"," '1970': 1,\n"," '2': 1,\n"," '263a': 1,\n"," '2f': 1,\n"," '2k': 2,\n"," '2m': 1,\n"," '2n': 13,\n"," '32k': 2,\n"," '3n': 1,\n"," '40k': 1,\n"," '44x': 1,\n"," '473l': 2,\n"," '4k': 1,\n"," '4n': 3,\n"," '4x16': 1,\n"," '5n': 1,\n"," '64k': 1,\n"," '7th': 1,\n"," '8k': 1,\n"," '8n': 1,\n"," '9n': 1,\n"," 'a': 5,\n"," 'a1': 28,\n"," 'a2': 1,\n"," 'a418': 1,\n"," 'a419': 1,\n"," 'a420': 1,\n"," 'a421': 1,\n"," 'a422': 1,\n"," 'a423': 1,\n"," 'a424': 1,\n"," 'a425': 1,\n"," 'a426': 1,\n"," 'a427': 1,\n"," 'a428': 1,\n"," 'a429': 1,\n"," 'a430': 1,\n"," 'a431': 1,\n"," 'a432': 1,\n"," 'a433': 1,\n"," 'a434': 1,\n"," 'a435': 1,\n"," 'a436': 1,\n"," 'a437': 1,\n"," 'a438': 1,\n"," 'a439': 1,\n"," 'a440': 1,\n"," 'a441': 1,\n"," 'a442': 1,\n"," 'a443': 1,\n"," 'a444': 1,\n"," 'a445': 1,\n"," 'a446': 1,\n"," 'a447': 1,\n"," 'a448': 1,\n"," 'a449': 1,\n"," 'a450': 1,\n"," 'a451': 1,\n"," 'a452': 1,\n"," 'a453': 1,\n"," 'a454': 1,\n"," 'a455': 1,\n"," 'a456': 1,\n"," 'a457': 1,\n"," 'a458': 1,\n"," 'a459': 1,\n"," 'a460': 1,\n"," 'a461': 1,\n"," 'a462': 1,\n"," 'a463': 1,\n"," 'a464': 1,\n"," 'a465': 1,\n"," 'a466': 1,\n"," 'a467': 1,\n"," 'a468': 1,\n"," 'a469': 1,\n"," 'a470': 1,\n"," 'a471': 1,\n"," 'a472': 1,\n"," 'a473': 1,\n"," 'a474': 1,\n"," 'a475': 1,\n"," 'a476': 1,\n"," 'a477': 1,\n"," 'a478': 1,\n"," 'a479': 1,\n"," 'a480': 1,\n"," 'a481': 1,\n"," 'a482': 1,\n"," 'a483': 1,\n"," 'a484': 1,\n"," 'a485': 1,\n"," 'a486': 1,\n"," 'a487': 1,\n"," 'aaron': 1,\n"," 'abac': 1,\n"," 'abacu': 1,\n"," 'abandon': 2,\n"," 'abbott': 1,\n"," 'abbrevi': 5,\n"," 'abcd': 1,\n"," 'abd': 1,\n"," 'abil': 30,\n"," 'abl': 16,\n"," 'abscissa': 3,\n"," 'absenc': 7,\n"," 'absolut': 11,\n"," 'absorb': 1,\n"," 'absorpt': 1,\n"," 'abstract': 73,\n"," 'academ': 13,\n"," 'academician': 1,\n"," 'accel': 8,\n"," 'accent': 1,\n"," 'accept': 39,\n"," 'access': 129,\n"," 'accid': 1,\n"," 'accommod': 5,\n"," 'accompani': 3,\n"," 'accomplish': 31,\n"," 'accord': 26,\n"," 'account': 41,\n"," 'accru': 2,\n"," 'accumul': 26,\n"," 'accur': 32,\n"," 'accuraci': 51,\n"," 'acf': 1,\n"," 'achiev': 76,\n"," 'acknowledg': 1,\n"," 'acl': 1,\n"," 'acm': 45,\n"," 'aco': 1,\n"," 'acqui': 2,\n"," 'acquir': 6,\n"," 'acquisit': 3,\n"," 'acronym': 1,\n"," 'act': 3,\n"," 'action': 38,\n"," 'activ': 83,\n"," 'actor': 1,\n"," 'actual': 46,\n"," 'acycl': 4,\n"," 'ad': 43,\n"," 'ada': 1,\n"," 'adam': 3,\n"," 'adapt': 45,\n"," 'add': 9,\n"," 'addend': 3,\n"," 'addendum': 6,\n"," 'adder': 4,\n"," 'addit': 125,\n"," 'address': 98,\n"," 'adept': 2,\n"," 'adequ': 13,\n"," 'adequaci': 5,\n"," 'adher': 1,\n"," 'adjac': 10,\n"," 'adjoin': 1,\n"," 'adjoint': 1,\n"," 'adjudg': 1,\n"," 'adjust': 15,\n"," 'administr': 22,\n"," 'admir': 1,\n"," 'admiss': 7,\n"," 'admit': 7,\n"," 'adopt': 10,\n"," 'adp': 1,\n"," 'advanc': 30,\n"," 'advantag': 89,\n"," 'advent': 3,\n"," 'adver': 2,\n"," 'advi': 1,\n"," 'advic': 1,\n"," 'advoc': 3,\n"," 'aeronaut': 2,\n"," 'aesthet': 1,\n"," 'affair': 1,\n"," 'affect': 18,\n"," 'affirm': 2,\n"," 'affix': 7,\n"," 'afford': 2,\n"," 'age': 3,\n"," 'agement': 1,\n"," 'agenc': 7,\n"," 'agenda': 2,\n"," 'agent': 1,\n"," 'aggrav': 1,\n"," 'aggreg': 13,\n"," 'ago': 4,\n"," 'agr': 3,\n"," 'agreement': 3,\n"," 'ahead': 1,\n"," 'ahren': 5,\n"," 'ai': 3,\n"," 'aid': 71,\n"," 'aim': 16,\n"," 'air': 4,\n"," 'aircraft': 2,\n"," 'airi': 2,\n"," 'airlin': 3,\n"," 'aitken': 2,\n"," 'akin': 1,\n"," 'al': 5,\n"," 'alan': 1,\n"," 'alarm': 1,\n"," 'albani': 1,\n"," 'albeit': 1,\n"," 'alcor': 5,\n"," 'aldep': 1,\n"," 'alert': 2,\n"," 'alg': 2,\n"," 'algebra': 97,\n"," 'algem': 4,\n"," 'algol': 178,\n"," 'algorithm': 1861,\n"," 'alia': 2,\n"," 'alien': 1,\n"," 'align': 5,\n"," 'alik': 1,\n"," 'alleg': 1,\n"," 'allegedli': 1,\n"," 'allevi': 3,\n"," 'alloc': 151,\n"," 'allow': 75,\n"," 'aloc': 1,\n"," 'aloof': 1,\n"," 'alpak': 1,\n"," 'alpha': 4,\n"," 'alphabet': 16,\n"," 'alpham': 2,\n"," 'alphanum': 8,\n"," 'alphard': 3,\n"," 'alter': 13,\n"," 'altern': 71,\n"," 'althm': 1,\n"," 'altogeth': 1,\n"," 'altran': 2,\n"," 'ambigu': 30,\n"," 'ambit': 5,\n"," 'ambiti': 2,\n"," 'amen': 1,\n"," 'amend': 2,\n"," 'american': 44,\n"," 'amesplot': 4,\n"," 'ammunit': 1,\n"," 'amount': 57,\n"," 'amp': 1,\n"," 'amphisbaen': 1,\n"," 'amplifi': 1,\n"," 'amplitud': 2,\n"," 'an': 2,\n"," 'analog': 18,\n"," 'analogu': 2,\n"," 'analysi': 319,\n"," 'analyst': 5,\n"," 'analyt': 49,\n"," 'analyz': 117,\n"," 'anarc': 1,\n"," 'anatomi': 2,\n"," 'ancestor': 3,\n"," 'ancient': 2,\n"," 'andri': 1,\n"," 'anew': 1,\n"," 'angel': 1,\n"," 'angl': 13,\n"," 'angular': 1,\n"," 'anim': 12,\n"," 'annex': 1,\n"," 'anniversari': 1,\n"," 'annot': 1,\n"," 'announc': 3,\n"," 'annoy': 1,\n"," 'annual': 2,\n"," 'anom': 5,\n"," 'anomali': 11,\n"," 'anpak': 1,\n"," 'ansi': 1,\n"," 'answer': 49,\n"," 'anticip': 5,\n"," 'anticipatori': 2,\n"," 'antilog': 1,\n"," 'aparel': 3,\n"," 'apertur': 6,\n"," 'apl': 6,\n"," 'apld': 2,\n"," 'appar': 5,\n"," 'appeal': 1,\n"," 'appear': 34,\n"," 'append': 3,\n"," 'appendix': 13,\n"," 'appli': 130,\n"," 'applic': 324,\n"," 'appoint': 5,\n"," 'apport': 1,\n"," 'apprai': 3,\n"," 'appreci': 4,\n"," 'approach': 162,\n"," 'appropri': 6,\n"," 'approxim': 159,\n"," 'apr': 2,\n"," 'april': 2,\n"," 'apt': 4,\n"," 'aquat': 1,\n"," 'ar': 1,\n"," 'arbitr': 1,\n"," 'arbitrari': 53,\n"," 'arbitrarili': 7,\n"," 'arboresc': 1,\n"," 'arc': 9,\n"," 'arccosin': 1,\n"," 'arccossin': 1,\n"," 'archaeolog': 2,\n"," 'archimedian': 1,\n"," 'architectur': 28,\n"," 'arctang': 2,\n"," 'ard': 2,\n"," 'area': 101,\n"," 'areext': 1,\n"," 'argentin': 1,\n"," 'argentina': 2,\n"," 'argu': 14,\n"," 'argument': 27,\n"," 'ari': 33,\n"," 'arithmet': 116,\n"," 'arm': 3,\n"," 'armament': 1,\n"," 'armi': 2,\n"," 'aro': 1,\n"," 'arpa': 5,\n"," 'arpanet': 3,\n"," 'arrang': 24,\n"," 'array': 90,\n"," 'arrhythmia': 1,\n"," 'arriv': 16,\n"," 'arrow': 1,\n"," 'art': 10,\n"," 'arteri': 2,\n"," 'arthur': 1,\n"," 'articl': 21,\n"," 'articul': 1,\n"," 'artifici': 14,\n"," 'artist': 1,\n"," 'asa': 8,\n"," 'ascend': 4,\n"," 'ascertain': 5,\n"," 'ascii': 7,\n"," 'ashenhurst': 2,\n"," 'ask': 5,\n"," 'asp': 5,\n"," 'aspect': 59,\n"," 'ass': 3,\n"," 'assembl': 58,\n"," 'assert': 24,\n"," 'assess': 10,\n"," 'assign': 68,\n"," 'assimil': 1,\n"," 'assist': 32,\n"," 'assoc': 1,\n"," 'associ': 38,\n"," 'assort': 2,\n"," 'assum': 48,\n"," 'assumpt': 31,\n"," 'assur': 5,\n"," 'asterionella': 1,\n"," 'astronaut': 1,\n"," 'astronomi': 1,\n"," 'asymmetr': 4,\n"," 'asymptot': 15,\n"," 'asynchron': 7,\n"," 'ativ': 2,\n"," 'atla': 9,\n"," 'atmosph': 1,\n"," 'atom': 8,\n"," 'attach': 7,\n"," 'attack': 4,\n"," 'attain': 8,\n"," 'attempt': 52,\n"," 'attend': 2,\n"," 'attent': 19,\n"," 'attenu': 1,\n"," 'attitud': 11,\n"," 'attract': 9,\n"," 'attribut': 27,\n"," 'auction': 2,\n"," 'audio': 2,\n"," 'augment': 14,\n"," 'august': 3,\n"," 'australia': 1,\n"," 'authent': 11,\n"," 'author': 47,\n"," 'auto': 3,\n"," 'autocod': 4,\n"," 'autocorrel': 5,\n"," 'autocovari': 1,\n"," 'autom': 45,\n"," 'automast': 1,\n"," 'automat': 159,\n"," 'automaton': 17,\n"," 'automobil': 1,\n"," 'automorph': 2,\n"," 'autonom': 2,\n"," 'auxiliari': 16,\n"," 'avail': 12,\n"," 'avenu': 4,\n"," 'aver': 1,\n"," 'averag': 66,\n"," 'avint': 1,\n"," 'avl': 12,\n"," 'avoid': 41,\n"," 'await': 1,\n"," 'awaken': 1,\n"," 'awar': 3,\n"," 'ax': 6,\n"," 'axi': 5,\n"," 'axial': 2,\n"," 'axiom': 13,\n"," 'axiomat': 7,\n"," 'axl': 2,\n"," 'ay1': 1,\n"," 'b1': 5,\n"," 'b2': 2,\n"," 'b205': 1,\n"," 'b3': 3,\n"," 'b5500': 4,\n"," 'b6500': 2,\n"," 'babylonian': 2,\n"," 'bachelor': 1,\n"," 'back': 18,\n"," 'backboard': 2,\n"," 'background': 17,\n"," 'backtrack': 7,\n"," 'backup': 3,\n"," 'backward': 12,\n"," 'bad': 5,\n"," 'bag': 1,\n"," 'bagdam': 2,\n"," 'bairstow': 8,\n"," 'baker': 1,\n"," 'balanc': 30,\n"," 'ballist': 2,\n"," 'baltimor': 1,\n"," 'band': 7,\n"," 'bandmatrix': 1,\n"," 'bandsolv': 2,\n"," 'bandwidth': 2,\n"," 'bank': 32,\n"," 'banker': 1,\n"," 'bar': 1,\n"," 'baran': 1,\n"," 'bargraph': 1,\n"," 'barnett': 1,\n"," 'barrier': 4,\n"," 'barstow': 1,\n"," 'base': 290,\n"," 'bashforth': 1,\n"," 'basi': 64,\n"," 'basic': 127,\n"," 'basin': 1,\n"," 'basser': 1,\n"," 'batch': 37,\n"," 'bauer': 1,\n"," 'bay': 2,\n"," 'bb': 1,\n"," 'bbn': 2,\n"," 'bc': 1,\n"," 'bcd': 6,\n"," 'bdl': 2,\n"," 'be': 1,\n"," 'beal': 3,\n"," 'bear': 4,\n"," 'beat': 1,\n"," 'bedford': 1,\n"," 'begin': 17,\n"," 'beginn': 2,\n"," 'begun': 2,\n"," 'behav': 1,\n"," 'behavior': 56,\n"," 'bei': 3,\n"," 'bel': 2,\n"," 'beladi': 1,\n"," 'belfap': 1,\n"," 'belief': 4,\n"," 'believ': 4,\n"," 'bell': 7,\n"," 'bellman': 5,\n"," 'belong': 5,\n"," 'belzer': 1,\n"," 'bench': 1,\n"," 'benchmark': 2,\n"," 'bend': 1,\n"," 'bendix': 2,\n"," 'benefici': 2,\n"," 'benefit': 18,\n"," 'ber': 3,\n"," 'berkeley': 3,\n"," 'bernard': 2,\n"," 'bernstein': 2,\n"," 'beset': 2,\n"," 'bessel': 19,\n"," 'bestow': 1,\n"," 'beta': 8,\n"," 'bezout': 4,\n"," 'bi': 1,\n"," 'bia': 4,\n"," 'bibliograph': 4,\n"," 'bibliographi': 7,\n"," 'biconnect': 1,\n"," 'bicub': 1,\n"," 'bidirect': 2,\n"," 'big': 1,\n"," 'bigger': 3,\n"," 'biharmon': 4,\n"," 'bill': 3,\n"," 'binari': 113,\n"," 'bind': 10,\n"," 'binomi': 6,\n"," 'biochem': 5,\n"," 'biochemci': 1,\n"," 'biolog': 10,\n"," 'biom': 2,\n"," 'biostatist': 1,\n"," 'bipartit': 3,\n"," 'bipha': 1,\n"," 'bisect': 3,\n"," 'bit': 103,\n"," 'bitwi': 1,\n"," 'bivari': 7,\n"," 'bk': 1,\n"," 'black': 3,\n"," 'blank': 3,\n"," 'blend': 1,\n"," 'blind': 8,\n"," 'bliss': 2,\n"," 'blnsi': 2,\n"," 'block': 113,\n"," 'blockag': 1,\n"," 'blood': 2,\n"," 'blown': 1,\n"," 'bmd': 2,\n"," 'bmdp': 1,\n"," 'bnf': 6,\n"," 'board': 7,\n"," 'bobrow': 1,\n"," 'bodi': 11,\n"," 'bohm': 1,\n"," 'bonanza': 1,\n"," 'bond': 2,\n"," 'bonu': 2,\n"," 'boo': 1,\n"," 'book': 3,\n"," 'booker': 1,\n"," 'bookkeep': 8,\n"," 'boolean': 37,\n"," 'boot': 1,\n"," 'boothroyd': 1,\n"," 'bootstrap': 6,\n"," 'border': 1,\n"," 'borrow': 1,\n"," 'boston': 1,\n"," 'bottleneck': 2,\n"," 'bottom': 9,\n"," 'bound': 98,\n"," 'boundari': 52,\n"," 'box': 3,\n"," 'boyer': 2,\n"," 'bracket': 1,\n"," 'brad': 3,\n"," 'braill': 8,\n"," 'brailler': 2,\n"," 'brain': 4,\n"," 'branch': 17,\n"," 'breach': 3,\n"," 'breadboard': 1,\n"," 'break': 6,\n"," 'breakdown': 4,\n"," 'breakthrough': 1,\n"," 'brent': 1,\n"," 'briefli': 35,\n"," 'brinch': 2,\n"," 'bring': 8,\n"," 'bro': 1,\n"," 'broad': 10,\n"," 'broadcast': 7,\n"," 'broaden': 1,\n"," 'broader': 3,\n"," 'broadli': 1,\n"," 'broken': 4,\n"," 'bromwich': 1,\n"," 'brooker': 2,\n"," 'brookhaven': 3,\n"," 'brother': 4,\n"," 'brought': 3,\n"," 'brow': 1,\n"," 'brown': 2,\n"," 'brute': 1,\n"," 'bryant': 2,\n"," 'bu': 1,\n"," 'bubbl': 4,\n"," 'bubget': 1,\n"," 'bucket': 9,\n"," 'buddi': 23,\n"," 'budget': 6,\n"," 'buffalo': 1,\n"," 'buffer': 35,\n"," 'buford': 1,\n"," 'bug': 1,\n"," 'bugsi': 3,\n"," 'build': 24,\n"," 'buildabl': 1,\n"," 'built': 20,\n"," 'bulirsh': 1,\n"," 'bulk': 3,\n"," 'bulki': 1,\n"," 'bundl': 1,\n"," 'burden': 2,\n"," 'burdensom': 1,\n"," 'bureau': 2,\n"," 'burnett': 1,\n"," 'burrough': 7,\n"," 'burst': 1,\n"," 'burstal': 1,\n"," 'busi': 39,\n"," 'butcher': 2,\n"," 'button': 1,\n"," 'buy': 2,\n"," 'bx': 2,\n"," 'byan': 1,\n"," 'bypass': 5,\n"," 'byproduct': 1,\n"," 'byte': 9,\n"," 'c1': 6,\n"," 'c191': 1,\n"," 'c2': 9,\n"," 'c266': 1,\n"," 'c3': 1,\n"," 'c363': 1,\n"," 'c379': 1,\n"," 'c380': 1,\n"," 'c386': 1,\n"," 'c404': 1,\n"," 'c407': 1,\n"," 'c446': 1,\n"," 'c451': 1,\n"," 'c5': 9,\n"," 'c6': 12,\n"," 'ca590406': 1,\n"," 'cabl': 1,\n"," 'cach': 5,\n"," 'cacm': 1,\n"," 'cadep': 2,\n"," 'cai': 3,\n"," 'calcul': 123,\n"," 'calculu': 21,\n"," 'calen': 1,\n"," 'calendar': 8,\n"," 'calibr': 1,\n"," 'california': 7,\n"," 'call': 119,\n"," 'caller': 1,\n"," 'callup': 1,\n"," 'calorimet': 1,\n"," 'cam': 3,\n"," 'cambridg': 1,\n"," 'came': 2,\n"," 'camera': 1,\n"," 'campaign': 1,\n"," 'campu': 2,\n"," 'cancel': 1,\n"," 'candid': 4,\n"," 'canon': 7,\n"," 'cap': 5,\n"," 'capabl': 97,\n"," 'capac': 17,\n"," 'capacit': 2,\n"," 'capit': 1,\n"," 'captur': 1,\n"," 'car': 7,\n"," 'card': 24,\n"," 'cardiac': 1,\n"," 'cardin': 2,\n"," 'cardiographi': 2,\n"," 'cardiovascular': 1,\n"," 'care': 19,\n"," 'carlo': 10,\n"," 'carnegi': 2,\n"," 'carolina': 2,\n"," 'carotid': 3,\n"," 'carri': 26,\n"," 'cartesian': 1,\n"," 'cartoon': 1,\n"," 'cascad': 4,\n"," 'case': 158,\n"," 'casework': 2,\n"," 'cash': 1,\n"," 'cast': 1,\n"," 'casual': 3,\n"," 'cat': 1,\n"," 'catalog': 6,\n"," 'catalogu': 2,\n"," 'catalyst': 1,\n"," 'catalystincorpor': 1,\n"," 'catastroph': 1,\n"," 'catch': 1,\n"," 'categor': 2,\n"," 'categori': 7,\n"," 'cater': 1,\n"," 'cathod': 6,\n"," 'catmul': 1,\n"," 'cau': 14,\n"," 'cauchi': 3,\n"," 'caught': 1,\n"," 'ccc': 2,\n"," 'ccd': 3,\n"," 'cdc': 21,\n"," 'cdr': 3,\n"," 'celesti': 5,\n"," 'cell': 28,\n"," 'cellar': 1,\n"," 'cellular': 9,\n"," 'censu': 3,\n"," 'cent': 1,\n"," 'center': 40,\n"," 'central': 34,\n"," 'centroid': 1,\n"," 'cep': 7,\n"," 'certainli': 2,\n"," 'certif': 11,\n"," 'cf': 2,\n"," 'cft': 3,\n"," 'ch': 1,\n"," 'chain': 33,\n"," 'chair': 1,\n"," 'chairman': 4,\n"," 'challeng': 2,\n"," 'chamber': 4,\n"," 'champ': 1,\n"," 'championship': 1,\n"," 'chanc': 2,\n"," 'chang': 47,\n"," 'changeabl': 1,\n"," 'channel': 14,\n"," 'charact': 149,\n"," 'characterist': 105,\n"," 'charg': 5,\n"," 'chargeout': 4,\n"," 'charl': 1,\n"," 'charlier': 2,\n"," 'chart': 11,\n"," 'chaudhuri': 1,\n"," 'cheap': 1,\n"," 'cheapli': 1,\n"," 'chebyschev': 4,\n"," 'chebyshev': 28,\n"," 'check': 46,\n"," 'checker': 4,\n"," 'checkerboard': 1,\n"," 'checklist': 1,\n"," 'checkout': 2,\n"," 'checkpoint': 4,\n"," 'checksum': 1,\n"," 'chemic': 7,\n"," 'chemistri': 4,\n"," 'chen': 1,\n"," 'cheney': 2,\n"," 'chess': 9,\n"," 'chi': 4,\n"," 'chief': 4,\n"," 'chile': 2,\n"," 'chilean': 1,\n"," 'china': 3,\n"," 'chine': 7,\n"," 'chino': 3,\n"," 'chip': 1,\n"," 'choic': 48,\n"," 'chomski': 3,\n"," 'choo': 15,\n"," 'chop': 4,\n"," 'chosen': 24,\n"," 'chrisoffel': 1,\n"," 'christoffel': 1,\n"," 'chromosom': 1,\n"," 'chronolog': 3,\n"," 'chunk': 1,\n"," 'church': 4,\n"," 'cigarett': 2,\n"," 'cincinnati': 2,\n"," 'cipher': 12,\n"," 'cipi': 1,\n"," 'circa': 2,\n"," 'circl': 8,\n"," 'circuit': 35,\n"," 'circul': 2,\n"," 'circular': 17,\n"," 'circumst': 9,\n"," 'circumv': 3,\n"," 'citat': 1,\n"," 'cite': 1,\n"," 'citi': 4,\n"," 'civil': 1,\n"," 'cl': 1,\n"," 'claim': 10,\n"," 'clarif': 5,\n"," 'clarifi': 11,\n"," 'clariti': 2,\n"," 'clark': 1,\n"," 'class': 144,\n"," 'classic': 20,\n"," 'classif': 18,\n"," 'classifi': 12,\n"," 'classroom': 3,\n"," 'clau': 4,\n"," 'clausal': 1,\n"," 'clean': 3,\n"," 'clear': 11,\n"," 'clearanc': 1,\n"," 'clearli': 6,\n"," 'clebsch': 1,\n"," 'clenshaw': 8,\n"," 'cleric': 1,\n"," 'clerk': 2,\n"," 'client': 3,\n"," 'climat': 1,\n"," 'clinic': 10,\n"," 'clip': 18,\n"," 'cliqu': 6,\n"," 'clock': 11,\n"," 'close': 41,\n"," 'closer': 2,\n"," 'closest': 2,\n"," 'closet': 2,\n"," 'closur': 5,\n"," 'cloud': 2,\n"," 'clp': 4,\n"," 'clu': 7,\n"," 'club': 1,\n"," 'clue': 1,\n"," 'cluster': 19,\n"," 'clutter': 1,\n"," 'co': 1,\n"," 'coastlin': 1,\n"," 'coaxial': 1,\n"," 'cobol': 69,\n"," 'cobolin': 1,\n"," 'cock': 2,\n"," 'coda': 2,\n"," 'codasyl': 3,\n"," 'codd': 1,\n"," 'code': 276,\n"," 'coder': 2,\n"," 'codeword': 5,\n"," 'codifi': 1,\n"," 'coeffici': 61,\n"," 'coercion': 1,\n"," 'coexist': 1,\n"," 'coffman': 2,\n"," 'cognat': 1,\n"," 'cognit': 1,\n"," 'cohe': 1,\n"," 'coher': 2,\n"," 'coif': 1,\n"," 'coin': 1,\n"," 'coincid': 3,\n"," 'coko': 6,\n"," 'cold': 6,\n"," 'colinear': 1,\n"," 'collat': 2,\n"," 'collect': 69,\n"," 'collector': 10,\n"," 'colleg': 19,\n"," 'colli': 7,\n"," 'collin': 3,\n"," 'color': 16,\n"," 'columbia': 1,\n"," 'column': 21,\n"," 'combat': 2,\n"," 'combin': 110,\n"," 'combinatori': 25,\n"," 'come': 10,\n"," 'comit': 7,\n"," 'comm': 9,\n"," 'comma': 1,\n"," 'command': 47,\n"," 'comment': 58,\n"," 'commentari': 1,\n"," 'commerci': 8,\n"," 'commiss': 2,\n"," 'commit': 1,\n"," 'committ': 27,\n"," 'common': 72,\n"," 'commonli': 20,\n"," 'commun': 110,\n"," 'communist': 3,\n"," 'commut': 1,\n"," 'compact': 32,\n"," 'compactifi': 3,\n"," 'compani': 5,\n"," 'companion': 3,\n"," 'compar': 146,\n"," 'comparison': 107,\n"," 'compass': 2,\n"," 'compat': 27,\n"," 'compen': 3,\n"," 'compet': 4,\n"," 'competit': 2,\n"," 'compil': 254,\n"," 'complement': 18,\n"," 'complementar': 2,\n"," 'complementari': 7,\n"," 'complet': 105,\n"," 'complex': 170,\n"," 'compli': 1,\n"," 'complic': 21,\n"," 'compo': 15,\n"," 'compon': 63,\n"," 'composit': 32,\n"," 'compound': 3,\n"," 'comprehen': 16,\n"," 'comprehend': 10,\n"," 'compress': 25,\n"," 'compressor': 2,\n"," 'compri': 3,\n"," 'compromi': 7,\n"," 'comput': 1620,\n"," 'con': 4,\n"," 'concaten': 9,\n"," 'concav': 3,\n"," 'conceiv': 4,\n"," 'concentr': 10,\n"," 'concept': 130,\n"," 'conceptu': 22,\n"," 'concern': 60,\n"," 'conci': 9,\n"," 'conclu': 26,\n"," 'conclud': 25,\n"," 'concord': 3,\n"," 'concret': 3,\n"," 'concurr': 26,\n"," 'conden': 6,\n"," 'condit': 136,\n"," 'conduc': 2,\n"," 'conduct': 20,\n"," 'confer': 7,\n"," 'confid': 2,\n"," 'confidenti': 5,\n"," 'configur': 36,\n"," 'confin': 8,\n"," 'confirm': 3,\n"," 'conflict': 20,\n"," 'confluent': 4,\n"," 'conform': 5,\n"," 'confront': 1,\n"," 'confu': 2,\n"," 'congress': 2,\n"," 'congruent': 1,\n"," 'congruenti': 5,\n"," 'conjectur': 4,\n"," 'conjug': 5,\n"," 'conjunct': 16,\n"," 'connect': 53,\n"," 'connot': 1,\n"," 'conquer': 1,\n"," 'consciou': 1,\n"," 'consecut': 14,\n"," 'consequ': 9,\n"," 'conserv': 1,\n"," 'consid': 219,\n"," 'considerd': 1,\n"," 'consist': 79,\n"," 'consol': 23,\n"," 'consolid': 3,\n"," 'constant': 42,\n"," 'constel': 1,\n"," 'constitu': 4,\n"," 'constitut': 10,\n"," 'constrain': 12,\n"," 'constraint': 48,\n"," 'construct': 179,\n"," 'consult': 2,\n"," 'consum': 18,\n"," 'consumm': 1,\n"," 'consumpt': 1,\n"," 'cont': 4,\n"," 'contact': 2,\n"," 'contactless': 1,\n"," 'contain': 18,\n"," 'contempl': 1,\n"," 'contemporari': 6,\n"," 'contend': 3,\n"," 'content': 36,\n"," 'context': 104,\n"," 'contextu': 2,\n"," 'contigu': 7,\n"," 'contin': 1,\n"," 'continu': 73,\n"," 'contour': 40,\n"," 'contract': 4,\n"," 'contradict': 2,\n"," 'contradictori': 2,\n"," ...}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Primero, obtenemos las frecuencias de las palabras\n","\n","from collections import Counter\n","\n","dict_freq = dict(sorted(Counter(doc_words).items()))\n","dict_freq\n","\n","#print(c.items())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# separando las palabras por documento:\n","# text\n","from itertools import count\n","from operator import countOf\n","\n","\n","words = re.split(r\"\\n\", text)\n","doc_words_per_doc = dict()\n","i = 1\n","for w in words:\n","    split = re.split(r\"\\|\", w)\n","    index = str(i)\n","    if len(split) == 1:\n","        continue\n","    elif len(split) == 4:\n","        doc_words_per_doc[i] = [x for x in split[2].split(\" \") if x]\n","    doc_words_per_doc[i] = [x for x in split[1].split(\" \") if x]\n","    i += 1\n","doc_words_per_doc[1]\n","\n","# contamos las frecuencias de cada término por documento\n","freq_per_doc = dict()\n","for d in doc_words_per_doc.keys():\n","    freq_per_doc[d] = dict().fromkeys(dict_freq.keys())\n","    for t in dict_freq.keys():\n","        freq_per_doc[d][t] = countOf(doc_words_per_doc[d], t)\n","        #print(t)\n","        \n","   \n","#{1: {\"premiliniari\": 1, \"report\": 3, ... , \"algorithm\": 0, ...}}\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# dict_freq         -> vector q\n","# freq_per_doc[1]   -> vector d"]},{"cell_type":"markdown","metadata":{},"source":["Ahora lo mismo pero con el vocabulario reducido"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["5178\n","4670\n"]}],"source":["import copy\n","filename = \"vocabulario_reducido_trunc.txt\"\n","file = open(filename, 'rt',encoding='utf-8-sig')\n","red_voc = file.read().split(\", \")\n","file.close()\n","red_voc = sorted(red_voc)\n","\n","new_voc = copy.copy(dict_freq)\n","#freq_per_doc_red = { key : value for (key, value) in dict_freq if key in red_voc }\n","del_keys = [ key for key in new_voc if key not in red_voc ]\n","for key in del_keys:\n","     del new_voc[key]\n","print(len(dict_freq))\n","print(len(new_voc))\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["freq_per_doc_red = dict()\n","for d in doc_words_per_doc.keys():\n","    freq_per_doc_red[d] = dict().fromkeys(new_voc.keys())\n","    for t in new_voc.keys():\n","        freq_per_doc_red[d][t] = countOf(doc_words_per_doc[d], t)\n","        \n","# new_voc           -> vector q reducido\n","# freq_per_doc_red  -> matriz d reducido"]},{"cell_type":"markdown","metadata":{},"source":["## Con queries\n","### Vocabulario normal"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["64\n"]}],"source":["filename = \"querys_trunc.txt\"\n","file = open(filename, 'rt',encoding='utf-8-sig')\n","text = file.read()\n","file.close()\n","import re\n","words = re.split(r\"\\n\", text)\n","quer_words_per_quer = dict()\n","i = 1\n","for w in words:\n","    split = re.split(r\"\\|\", w)\n","    index = str(i)\n","    if len(split) == 1:\n","        continue\n","    elif len(split) == 4:\n","        quer_words_per_quer[i] = [x for x in split[2].split(\" \") if x]\n","    quer_words_per_quer[i] = [x for x in split[1].split(\" \") if x]\n","    i += 1\n","quer_words_per_quer[1]\n","print(len(quer_words_per_quer))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["freq_per_quer = dict()\n","for d in quer_words_per_quer.keys():\n","    freq_per_quer[d] = dict().fromkeys(dict_freq.keys())\n","    for t in dict_freq.keys():\n","        freq_per_quer[d][t] = countOf(quer_words_per_quer[d], t)\n","        #print(t)\n","\n","# dict_freq         -> vector q\n","# freq_per_quer     -> vector d"]},{"cell_type":"markdown","metadata":{},"source":["### Vocabulario reducido"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["freq_per_quer_red = dict()\n","for d in quer_words_per_quer.keys():\n","    freq_per_quer_red[d] = dict().fromkeys(new_voc.keys())\n","    for t in new_voc.keys():\n","        freq_per_quer_red[d][t] = countOf(quer_words_per_quer[d], t)\n","\n","\n","# new_voc         -> vector q\n","# freq_per_quer_red     -> vector d"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]}],"source":["print(freq_per_quer[1][\"tss\"])\n","#print(freq_per_quer_red[1][\"tss\"])"]},{"cell_type":"markdown","metadata":{},"source":["## Con tf-idf"]},{"cell_type":"markdown","metadata":{},"source":["Calcularemos primero un vector con los valores de frecuencia inversa del doc (idf)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#primero, calculamos N_t (# de docs con el término)\n","N_t = dict().fromkeys(dict_freq.keys())\n","N_t = { x : 0 for x in N_t}\n","for i in N_t.keys():\n","    for j in freq_per_doc.keys():\n","        if freq_per_doc[j][i] != 0:\n","            N_t[i] += 1"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["contract = 0\n","for i in freq_per_doc:\n","    if freq_per_doc[i][\"contract\"] != 0:\n","        contract += 1\n","contract"]}],"metadata":{"colab":{"name":"p1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"8bac3ed83652cd3fb2be2ab4720f126b858190479445937cf7f7241afc53dfb0"}}},"nbformat":4,"nbformat_minor":0}
