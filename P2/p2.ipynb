{"cells":[{"cell_type":"markdown","metadata":{"id":"F4qwv6V8DiGv"},"source":["# Laboratorio 2: Recuperación de Información\n","**Objetivo:** \n","Aprender a preparar los textos para que sean de utilidad en el proceso de recuperación de información. Para ello deberás separar el texto en tokens, eliminarse los tokens inútiles (signos de puntuación, números, palabras vacías, convertir a minúsculas y truncar las palabras."]},{"cell_type":"markdown","metadata":{"id":"PudnwJzRDiG7"},"source":["**1. Utiliza el mismo e-book en texto plano del Lab1 (Around the World in Eight Days by Jules Verne)\n","https://www.gutenberg.org/files/103/103-0.txt**\n","\n","**2. Realizar el mismo pre-procesamiento de la practica 1 y como ultimo paso trunca las palabras utilixando del algortmo de Porter Stemming incluido en NLTK.**"]},{"cell_type":"markdown","metadata":{},"source":["Pre-procesamiento de la Practica 1"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"elapsed":312,"status":"error","timestamp":1661280866869,"user":{"displayName":"ALFONSO REYES D ELIA","userId":"17643141632695819125"},"user_tz":300},"id":"_ZpCn7NsDiG9","outputId":"7a24f2ee-ec2f-44f6-ca36-82fe374f04b8"},"outputs":[],"source":["filename = \"julioverne.txt\"\n","file = open(filename, 'rt',encoding='utf-8-sig')\n","text = file.read()\n","file.close()"]},{"cell_type":"markdown","metadata":{"id":"25VAvSf1DiHA"},"source":["Separamos el texto por palabras utilizando el espacio como delimitador "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0ECRYWipDiHC","outputId":"1723a996-190e-4e50-c343-15a4939a4169"},"outputs":[{"name":"stdout","output_type":"stream","text":["Las primeras 100 palabras\n","\n","['The', 'Project', 'Gutenberg', 'eBook', 'of', 'Around', 'the', 'World', 'in', 'Eighty', 'Days,', 'by', 'Jules', 'Verne', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever.', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States,', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook.', 'Title:', 'Around', 'the', 'World']\n"]}],"source":["words = text.split()\n","print(\"Las primeras 100 palabras\\n\")\n","print(words[:100])"]},{"cell_type":"markdown","metadata":{"id":"cb8p8V0rDiHF"},"source":["Utilizamos re de python para eliminar signos de puntuación. "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"95YfuRFNDiHG","outputId":"af3d3ec4-f235-468d-f1e5-8965f666a769"},"outputs":[{"name":"stdout","output_type":"stream","text":["Texto sin signos de Putuación\n","\n","['The', 'Project', 'Gutenberg', 'eBook', 'of', 'Around', 'the', 'World', 'in', 'Eighty', 'Days', 'by', 'Jules', 'Verne', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', 'Title']\n"]}],"source":["import re\n","words = re.split(r'\\W+',text)\n","print(\"Texto sin signos de Putuación\\n\")\n","print(words[:100])"]},{"cell_type":"markdown","metadata":{"id":"aA88IKxyDiHN"},"source":["Convertimos a minúsculas el texto, usando lower()."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"l5PMgua_DiHP","outputId":"044af51b-8e40-4fd9-988d-6bd831cdbe69"},"outputs":[{"name":"stdout","output_type":"stream","text":["*****Texto con Minusculas*****\n","\n","['the', 'project', 'gutenberg', 'ebook', 'of', 'around', 'the', 'world', 'in', 'eighty', 'days', 'by', 'jules', 'verne', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'united', 'states', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'if', 'you', 'are', 'not', 'located', 'in', 'the', 'united', 'states', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'ebook', 'title']\n"]}],"source":["import string\n","text_lower = text.lower()\n","words = re.split(r'\\W+',text_lower)\n","re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n","words_lower = [re_punc.sub(\"\",w) for w in words]\n"," \n","\n","print(\"*****Texto con Minusculas*****\\n\")\n","print(words_lower[:100])"]},{"cell_type":"markdown","metadata":{"id":"PFhxOZPUDiHR"},"source":["Eliminamos las palabras vacías"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gawHXVG0DiHU","outputId":"4a950bdd-832c-4b98-b3b4-0ca5babaa697"},"outputs":[{"name":"stdout","output_type":"stream","text":["['project', 'gutenberg', 'ebook', 'around', 'world', 'eighty', 'days', 'jules', 'verne', 'ebook', 'use', 'anyone', 'anywhere', 'united', 'states', 'parts', 'world', 'cost', 'almost', 'restrictions', 'whatsoever', 'may', 'copy', 'give', 'away', 'use', 'terms', 'project', 'gutenberg', 'license', 'included', 'ebook', 'online', 'www', 'gutenberg', 'org', 'located', 'united', 'states', 'check', 'laws', 'country', 'located', 'using', 'ebook', 'title', 'around', 'world', 'eighty', 'days', 'author', 'jules', 'verne', 'translator', 'g', 'towle', 'release', 'date', 'january', '1994', 'ebook', '103', 'recently', 'updated', 'august', '6', '2021', 'language', 'english', 'character', 'set', 'encoding', 'utf', '8', 'start', 'project', 'gutenberg', 'ebook', 'around', 'world', 'eighty', 'days', 'illustration', 'around', 'world', 'eighty', 'days', 'jules', 'verne', 'contents', 'chapter', 'phileas', 'fogg', 'passepartout', 'accept', 'one', 'master', 'man', 'chapter', 'ii']\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\poncho\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["# Primero, es necesario descargar las stopwords de la red\n","import nltk\n","nltk.download('stopwords')\n","\n","# Ahora, ya se pueden importar estas palabras sin mucho problema\n","from nltk.corpus import stopwords\n","stop_words = stopwords.words('english')\n","\n","# Para eliminar las palabras vacías, se hace uso de las operaciones de list comprehension de python\n","words_notStopWords = [x for x in words_lower if x not in stop_words]\n","print(words_notStopWords[:100])"]},{"cell_type":"markdown","metadata":{},"source":["Quitamos los números del texto numeros"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['project', 'gutenberg', 'ebook', 'around', 'world', 'eighty', 'days', 'jules', 'verne', 'ebook', 'use', 'anyone', 'anywhere', 'united', 'states', 'parts', 'world', 'cost', 'almost', 'restrictions', 'whatsoever', 'may', 'copy', 'give', 'away', 'use', 'terms', 'project', 'gutenberg', 'license', 'included', 'ebook', 'online', 'www', 'gutenberg', 'org', 'located', 'united', 'states', 'check', 'laws', 'country', 'located', 'using', 'ebook', 'title', 'around', 'world', 'eighty', 'days', 'author', 'jules', 'verne', 'translator', 'g', 'towle', 'release', 'date', 'january', 'ebook', 'recently', 'updated', 'august', 'language', 'english', 'character', 'set', 'encoding', 'utf', 'start', 'project', 'gutenberg', 'ebook', 'around', 'world', 'eighty', 'days', 'illustration', 'around', 'world', 'eighty', 'days', 'jules', 'verne', 'contents', 'chapter', 'phileas', 'fogg', 'passepartout', 'accept', 'one', 'master', 'man', 'chapter', 'ii', 'passepartout', 'convinced', 'last', 'found', 'ideal']\n"]}],"source":["words_filtered = [x for x in words_notStopWords if not x.isdigit()]\n","print(words_filtered[:100])"]},{"cell_type":"markdown","metadata":{},"source":["**Importamos el algortimo Porter Stemming incluido en NLTK**\n","\n","Escribimos las primeras 100 palabras ¿Que observas? ¿Hay cambios?"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['project', 'gutenberg', 'ebook', 'around', 'world', 'eighti', 'day', 'jule', 'vern', 'ebook', 'use', 'anyon', 'anywher', 'unit', 'state', 'part', 'world', 'cost', 'almost', 'restrict', 'whatsoev', 'may', 'copi', 'give', 'away', 'use', 'term', 'project', 'gutenberg', 'licens', 'includ', 'ebook', 'onlin', 'www', 'gutenberg', 'org', 'locat', 'unit', 'state', 'check', 'law', 'countri', 'locat', 'use', 'ebook', 'titl', 'around', 'world', 'eighti', 'day', 'author', 'jule', 'vern', 'translat', 'g', 'towl', 'releas', 'date', 'januari', 'ebook', 'recent', 'updat', 'august', 'languag', 'english', 'charact', 'set', 'encod', 'utf', 'start', 'project', 'gutenberg', 'ebook', 'around', 'world', 'eighti', 'day', 'illustr', 'around', 'world', 'eighti', 'day', 'jule', 'vern', 'content', 'chapter', 'philea', 'fogg', 'passepartout', 'accept', 'one', 'master', 'man', 'chapter', 'ii', 'passepartout', 'convinc', 'last', 'found', 'ideal']\n"]}],"source":["import nltk\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n","palabras_truncadas=[]\n","for word in words_filtered:\n","   palabras_truncadas.append(stemmer.stem(word))\n","print(palabras_truncadas[:100])"]},{"cell_type":"markdown","metadata":{},"source":["**3. Escribe tus observaciones.**\n","\n","Como podemos observar se han quitado las ultimas partes de algunas palabras, ya que Stemming o el trucamiento de las palabras es es un método de normalización de palabras en el procesamiento del lenguaje natural. En este método, se normalizan las palabras que tienen el mismo significado pero tienen algunas variaciones según el contexto o la oración.\n"]},{"cell_type":"markdown","metadata":{},"source":["**4. Investiga como utilizar**\n","\n","***a)nltk.stem.SnowBallStemmer()***"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['project', 'gutenberg', 'ebook', 'around', 'world', 'eighti', 'day', 'jule', 'vern', 'ebook', 'use', 'anyon', 'anywher', 'unit', 'state', 'part', 'world', 'cost', 'almost', 'restrict', 'whatsoev', 'may', 'copi', 'give', 'away', 'use', 'term', 'project', 'gutenberg', 'licens', 'includ', 'ebook', 'onlin', 'www', 'gutenberg', 'org', 'locat', 'unit', 'state', 'check', 'law', 'countri', 'locat', 'use', 'ebook', 'titl', 'around', 'world', 'eighti', 'day', 'author', 'jule', 'vern', 'translat', 'g', 'towl', 'releas', 'date', 'januari', 'ebook', 'recent', 'updat', 'august', 'languag', 'english', 'charact', 'set', 'encod', 'utf', 'start', 'project', 'gutenberg', 'ebook', 'around', 'world', 'eighti', 'day', 'illustr', 'around', 'world', 'eighti', 'day', 'jule', 'vern', 'content', 'chapter', 'philea', 'fogg', 'passepartout', 'accept', 'one', 'master', 'man', 'chapter', 'ii', 'passepartout', 'convinc', 'last', 'found', 'ideal']\n"]}],"source":["#Importamos SnowBallStemmer()\n","import nltk\n","from nltk.stem.snowball import SnowballStemmer\n","  \n","#El SnowBallStemmer requiere un campo de el idioma que vamos a leer \n","snow_stemmer = SnowballStemmer(language='english')\n","\n","palabras_Snowball=[]\n","for word in words_filtered:\n","   palabras_Snowball.append(snow_stemmer.stem(word)) #utilizamos el SnowballStemmer\n","print(palabras_Snowball[:100])\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","***b)nltk.wordnet.WordNetLemmatizer()***"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\poncho\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\poncho\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["['project', 'gutenberg', 'ebook', 'around', 'world', 'eighty', 'day', 'jules', 'verne', 'ebook', 'use', 'anyone', 'anywhere', 'united', 'state', 'part', 'world', 'cost', 'almost', 'restriction', 'whatsoever', 'may', 'copy', 'give', 'away', 'use', 'term', 'project', 'gutenberg', 'license', 'included', 'ebook', 'online', 'www', 'gutenberg', 'org', 'located', 'united', 'state', 'check', 'law', 'country', 'located', 'using', 'ebook', 'title', 'around', 'world', 'eighty', 'day', 'author', 'jules', 'verne', 'translator', 'g', 'towle', 'release', 'date', 'january', 'ebook', 'recently', 'updated', 'august', 'language', 'english', 'character', 'set', 'encoding', 'utf', 'start', 'project', 'gutenberg', 'ebook', 'around', 'world', 'eighty', 'day', 'illustration', 'around', 'world', 'eighty', 'day', 'jules', 'verne', 'content', 'chapter', 'phileas', 'fogg', 'passepartout', 'accept', 'one', 'master', 'man', 'chapter', 'ii', 'passepartout', 'convinced', 'last', 'found', 'ideal']\n"]}],"source":["#Importamos WordNetLemmatizer\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')  \n","nltk.download('omw-1.4')\n","lemmatizer = WordNetLemmatizer()\n","\n","palabras_Lemmatizer=[]\n","for word in words_filtered:\n","   palabras_Lemmatizer.append(lemmatizer.lemmatize(word)) #utilizamos el Lemmatizer\n","print(palabras_Lemmatizer[:100])"]},{"cell_type":"markdown","metadata":{},"source":["**5. Ejecútalos sobre el mismo e-book escibe las 100 primeras palabras, compara las\n","tres herramientas y obtengan sus conclusiones. Si alguna de ellas tarda\n","demasiado considera elegir una porción del texto.**\n","\n","Al comparar las tres herramientas concluimos que el algoritmo Porter Stemmer y el de SnowballStemmer hacen practicamente los mismos cambios al texto. En cambio, el WordNetLemmatizer es menos agresivo, ya que muchas palabras no cambiaron a comparación de los otros algoritmos.  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# comparando longitudes de vocabularios\n","voc = list(dict.fromkeys(words_filtered))\n","voc1 = list(dict.fromkeys(palabras_truncadas))\n","voc2 = list(dict.fromkeys(palabras_Snowball))\n","voc3 = list(dict.fromkeys(palabras_Lemmatizer))\n","print(\"Length voc \" + str(len(voc)))\n","print(\"Length voc1 \" + str(len(voc1)))\n","print(\"Length voc2 \" + str(len(voc2)))\n","print(\"Length voc3 \" + str(len(voc3)))\n"]}],"metadata":{"colab":{"name":"p1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"8bac3ed83652cd3fb2be2ab4720f126b858190479445937cf7f7241afc53dfb0"}}},"nbformat":4,"nbformat_minor":0}
